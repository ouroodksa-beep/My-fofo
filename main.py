import telebot
import requests
from bs4 import BeautifulSoup
import random
import re

# Ø§Ù„ØªÙˆÙƒÙ† Ø­Ù‚Ùƒ
API_TOKEN = '8534031232:AAHwBJ0HZvOlbDmeevlbd2zM9FvSIfeskjk'
bot = telebot.TeleBot(API_TOKEN)

def clean_title(full_title):
    # Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ø§Ø³Ù… Ø¨Ø£Ø®Ø° Ø£ÙˆÙ„ 6 ÙƒÙ„Ù…Ø§Øª ÙÙ‚Ø· Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ù‚Ø·Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
    words = full_title.split()
    if len(words) > 6:
        return " ".join(words[:6]) + ".."
    return full_title

def get_product_data(url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
            "Accept-Language": "ar-SA,en-US;q=0.9,ar;q=0.8",
        }
        
        res = requests.get(url, headers=headers, timeout=20, allow_redirects=True)
        soup = BeautifulSoup(res.content, 'html.parser')

        # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ø®ØªØµØ§Ø±Ù‡ Ø¨Ø°ÙƒØ§Ø¡ (ÙƒÙ„Ù…Ø§Øª ÙƒØ§Ù…Ù„Ø©)
        title_tag = soup.find("span", {"id": "productTitle"}) or soup.find("meta", property="og:title")
        raw_title = title_tag.get_text().strip() if title_tag else "Ù…Ù†ØªØ¬ Ù…Ù…ÙŠØ²"
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³Ù… Ù…Ù† ÙƒÙ„Ù…Ø© Amazon ÙˆØºÙŠØ±Ù‡Ø§
        raw_title = raw_title.replace("Amazon.sa :", "").replace("Amazon.sa:", "").strip()
        product_name = clean_title(raw_title)

        # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¹Ø±
        price = "Ø³Ø¹Ø± Ù„Ù‚Ø·Ø©!"
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø³Ø­Ø¨ Ø§Ù„Ø³Ø¹Ø± Ù…Ù† Ø§Ù„Ù€ Offscreen Ø£ÙˆÙ„Ø§Ù‹ (Ø§Ù„Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© ÙÙŠ Ø£Ù…Ø§Ø²ÙˆÙ†)
        price_tag = soup.select_one(".a-price .a-offscreen")
        if price_tag:
            price = price_tag.get_text().strip()
        else:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø© Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ø³Ø¹Ø± Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Ù†Ø§Øª Ø§Ù„Ù…Ù†ÙØµÙ„Ø©
            p_whole = soup.find("span", {"class": "a-price-whole"})
            if p_whole:
                price = p_whole.get_text().strip().replace(".", "") + " Ø±ÙŠØ§Ù„"

        # 3. Ø³Ø­Ø¨ Ø§Ù„ØµÙˆØ±Ø© (Ø£Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø©)
        img_url = None
        img_tag = soup.find("img", {"id": "landingImage"})
        if img_tag and img_tag.has_attr('data-a-dynamic-image'):
            img_data = img_tag.get('data-a-dynamic-image')
            img_url = list(eval(img_data).keys())[-1]
        elif img_tag:
            img_url = img_tag.get('src')

        # 4. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù†Ø´ÙˆØ± (5 Ø³Ø·ÙˆØ± Ù…Ø±ØªØ¨Ø©)
        intros = ["ÙŠØ§ Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡.. Ø´ÙˆÙÙˆØ§ Ù‡Ø§Ù„Ù„Ù‚Ø·Ø©! ğŸ˜", "Ø¬Ø¨Øª Ù„ÙƒÙ… Ø²ÙŠÙ† Ø§Ù„Ù‚Ù†ØµØ§Øª ğŸ”¥", "Ù„Ù‚Ø·Ø© Ø§Ù„ÙŠÙˆÙ… Ù„Ø§ ØªÙÙˆØªÙƒÙ… âœ¨"]
        descs = ["Ø¬ÙˆØ¯Ø© ÙˆÙØ®Ø§Ù…Ø© ÙˆØªØ³ØªØ§Ù‡Ù„ÙƒÙ….", "Ø´ÙŠØ¡ Ù…Ù† Ø§Ù„Ø¢Ø®Ø± ÙˆÙŠØ¨ÙŠØ¶ Ø§Ù„ÙˆØ¬Ù‡.", "Ø±Ù‡ÙŠØ¨ ÙˆØªÙ‚ÙŠÙŠÙ…Ù‡ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹."]
        
        caption = (
            f"{random.choice(intros)}\n"
            f"ğŸ“¦ **Ø§Ù„Ù…Ù†ØªØ¬:** {product_name}\n"
            f"ğŸ’° **Ø§Ù„Ø³Ø¹Ø±:** {price}\n"
            f"ğŸ‘Œ {random.choice(descs)}\n"
            f"ğŸ”— **Ø§Ù„Ø±Ø§Ø¨Ø·:** {url}"
        )
        
        return caption, img_url
    except Exception as e:
        print(f"Error: {e}")
        return None, None

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    if "http" in message.text:
        url_match = re.search(r'(https?://\S+)', message.text)
        if url_match:
            url = url_match.group(0)
            bot.send_chat_action(message.chat.id, 'upload_photo')
            caption, img_url = get_product_data(url)
            
            if caption:
                if img_url:
                    try:
                        bot.send_photo(message.chat.id, img_url, caption=caption, parse_mode='Markdown')
                    except:
                        bot.send_message(message.chat.id, caption, parse_mode='Markdown')
                else:
                    bot.send_message(message.chat.id, caption, parse_mode='Markdown')
            else:
                bot.reply_to(message, "Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø§ Ø³Ø­Ø¨ Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø¬Ø±Ø¨ÙŠ Ø±Ø§Ø¨Ø· Ø«Ø§Ù†ÙŠ ğŸ’”")

print("Ø§Ù„Ø¨ÙˆØª Ø´ØºØ§Ù„.. ÙˆØ¬Ø§Ù‡Ø² Ù„Ù„ÙØ²Ø¹Ø©!")
bot.polling()
