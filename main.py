import telebot
import cloudscraper
from bs4 import BeautifulSoup
import random
import re
import os
from flask import Flask
from threading import Thread

# --- Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ Ù„Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø¨ÙˆØª Ø­ÙŠØ§Ù‹ ---
app = Flask('')
@app.route('/')
def home(): return "Ø§Ù„Ø¨ÙˆØª Ø´ØºØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­!"

def run():
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)

def keep_alive():
    t = Thread(target=run)
    t.start()

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª ---
API_TOKEN = '8534031232:AAHwBJ0HZvOlbDmeevlbd2zM9FvSIfeskjk'
bot = telebot.TeleBot(API_TOKEN)
scraper = cloudscraper.create_scraper(browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False})

# Ø¨Ù†Ùƒ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ (Ø£ÙƒØ«Ø± Ù…Ù† 100 Ø®ÙŠØ§Ø±)
price_labels = ["Ø¨ÙƒÙ…ØŸ", "Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­ÙŠÙ†:", "Ø¨ÙƒÙ… Ù‡Ø§Ù„Ø²ÙŠÙ†ØŸ", "Ø³Ø¹Ø±Ù‡ Ø§Ù„Ù„Ù‚Ø·Ø©:", "Ù‚ÙŠÙ…Ø© Ø§Ù„Ù‚Ø·Ø¹Ø©:"]
intros = [
    "ÙŠØ§ Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡.. Ø´ÙˆÙÙˆØ§ Ù‡Ø§Ù„Ù„Ù‚Ø·Ø©! ğŸ˜", "Ø¬Ø¨Øª Ù„ÙƒÙ… Ø²ÙŠÙ† Ø§Ù„Ù‚Ù†ØµØ§Øª ğŸ”¥", "Ù„Ù‚Ø·Ø© Ø§Ù„ÙŠÙˆÙ… Ù„Ø§ ØªÙÙˆØªÙƒÙ… âœ¨", 
    "Ø§Ø¨Ø´Ø±ÙˆØ§ Ø¨Ø§Ù„Ø²ÙŠÙ†.. Ø´ÙˆÙÙˆØ§ ÙˆØ´ Ù„Ù‚ÙŠØª ğŸ’", "Ù‚Ù†ØµØ© Ø§Ù„ÙŠÙˆÙ… ÙˆØµÙ„Øª ÙŠØ§Ù„Ø±Ø¨Ø¹ ğŸ¯", "Ù„Ù‚ÙŠØª Ù„ÙƒÙ… Ø´ÙŠ ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³ ğŸ˜",
    "ÙŠØ§ Ø­ÙŠ Ø§Ù„Ù„Ù‡ Ù‡Ø§Ù„Ø·Ù„Ø©.. Ø´ÙŠ ÙÙ†Ø§Ù† ğŸŒŸ", "ØªØ¨ÙˆÙ† Ø§Ù„ØµØ¯Ù‚ØŸ Ù‡Ø§Ù„Ù‚Ø·Ø¹Ø© Ù…Ø§ ØªØªÙÙˆØª ğŸš€"
]
descs = [
    "Ø´ÙŠØ¡ ÙØ§Ø®Ø± ÙˆÙ…Ù† Ø§Ù„Ø¢Ø®Ø± ÙˆÙŠØ³ØªØ§Ù‡Ù„ÙƒÙ….", "Ø§Ù„Ø²ÙŠÙ† Ù…Ø§ ÙŠÙƒÙ…Ù„ Ø¥Ù„Ø§ Ø¨Ù‡ØŒ Ø¬ÙˆØ¯Ø© ÙˆØ³Ø¹Ø±.", "Ø±Ù‡ÙŠØ¨ ÙˆÙÙ†Ø§Ù† ÙˆØªØµÙ…ÙŠÙ…Ù‡ ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³.", 
    "ØªÙ‚ÙŠÙŠÙ…Ù‡ ÙŠØ·Ù…Ù† ÙˆØ¨ØµØ±Ø§Ø­Ø© Ù…Ø§ ÙŠØªÙÙˆØª.", "Ø®Ø§Ù…Ø© Ù…Ù…ØªØ§Ø²Ø© ÙˆØ³Ø¹Ø±Ù‡Ø§ ÙŠØ§ Ø¨Ù„Ø§Ø´ ÙˆØ§Ù„Ù„Ù‡.", "ÙˆØ§Ù„Ù„Ù‡ Ù„Ùˆ Ù…Ø§Ù‡Ùˆ Ø¨Ø·Ù„ Ù…Ø§ Ø¬Ø¨ØªÙ‡ Ù„ÙƒÙ…."
]

def clean_product_title(title):
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø²ÙˆØ§Ø¦Ø¯ ÙˆØ¨Ù‚Ø§Ø¡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ø§Ù„Ø¨Ø±Ø§Ù†Ø¯)
    title = title.replace("Amazon.sa :", "").replace("Amazon.sa:", "").strip()
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ ÙˆØ®Ø° Ø£ÙˆÙ„ 10-12 ÙƒÙ„Ù…Ø© Ù„Ø¶Ù…Ø§Ù† Ø³Ø·Ø±ÙŠÙ† ÙÙ‚Ø·
    words = title.split()
    if len(words) > 12:
        return " ".join(words[:12]) + ".."
    return title

def get_product_data(url):
    try:
        res = scraper.get(url, timeout=30)
        soup = BeautifulSoup(res.content, 'html.parser')

        # 1. Ø³Ø­Ø¨ Ø§Ù„Ø§Ø³Ù… (Ø¹Ø±Ø¨ÙŠ Ù…Ø®ØªØµØ± + Ø¨Ø±Ø§Ù†Ø¯ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)
        title_tag = soup.select_one('#productTitle') or soup.find("meta", property="og:title")
        product_info = "Ù…Ù†ØªØ¬ Ù…Ù…ÙŠØ²"
        if title_tag:
            product_info = clean_product_title(title_tag.get_text().strip())

        # 2. Ø³Ø­Ø¨ Ø§Ù„Ø³Ø¹Ø± (Ø¨Ø¯ÙˆÙ† Ù‡Ù„Ù„Ø§Øª ÙˆØ¨Ø¯ÙˆÙ† Ù†Ù‚Ø§Ø·)
        price = "Ø´ÙŠÙƒ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· ğŸ·ï¸"
        selectors = [
            'span.a-price-whole', '.a-price .a-offscreen', 
            '#corePrice_feature_div .a-offscreen', '#corePriceDisplay_desktop_feature_div .a-offscreen',
            '.a-color-price'
        ]
        for sel in selectors:
            p_tag = soup.select_one(sel)
            if p_tag and p_tag.get_text().strip():
                p_text = p_tag.get_text().strip().split('.')[0] # Ø­Ø°Ù Ø§Ù„Ù‡Ù„Ù„Ø§Øª
                clean_p = re.sub(r'[^\d]', '', p_text) # Ø£Ø±Ù‚Ø§Ù… ÙÙ‚Ø·
                if clean_p:
                    price = f"{clean_p} Ø±ÙŠØ§Ù„"
                    break

        # 3. Ø³Ø­Ø¨ Ø§Ù„ØµÙˆØ±Ø©
        img_url = None
        img_tag = soup.select_one('#landingImage') or soup.select_one('#main-image')
        if img_tag and img_tag.has_attr('data-a-dynamic-image'):
            links = re.findall(r'(https?://[^\s"]+)', img_tag['data-a-dynamic-image'])
            img_url = links[-1] if links else img_tag.get('src')
        elif img_tag:
            img_url = img_tag.get('src')

        # 4. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ø§Ù„Ø³Ø·Ø± Ø§Ù„ÙØ§Ø¶ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ù„ÙŠÙ†Ùƒ Ù…ÙˆØ¬ÙˆØ¯)
        caption = (
            f"{random.choice(intros)}\n\n"
            f"ğŸ“¦ **Ø§Ù„Ù…Ù†ØªØ¬:** {product_info}\n\n"
            f"ğŸ’° **{random.choice(price_labels)}** {price}\n"
            f"ğŸ‘Œ {random.choice(descs)}\n\n"
            f"ğŸ”— **Ø±Ø§Ø¨Ø· Ø§Ù„Ø·Ù„Ø¨:** {url}"
        )
        return caption, img_url
    except:
        return None, None

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    if "http" in message.text:
        url_match = re.search(r'(https?://\S+)', message.text)
        if url_match:
            url = url_match.group(0)
            bot.send_chat_action(message.chat.id, 'upload_photo')
            caption, img_url = get_product_data(url)
            if caption:
                try:
                    if img_url: bot.send_photo(message.chat.id, img_url, caption=caption, parse_mode='Markdown')
                    else: bot.send_message(message.chat.id, caption, parse_mode='Markdown')
                except:
                    bot.send_message(message.chat.id, caption, parse_mode='Markdown')

if __name__ == "__main__":
    keep_alive()
    bot.polling(none_stop=True)
