import telebot
import cloudscraper
from bs4 import BeautifulSoup
import random
import re
import os
from flask import Flask
from threading import Thread
from googletrans import Translator

# --- Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ Ù„Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø¨ÙˆØª Ø­ÙŠØ§Ù‹ ---
app = Flask('')
@app.route('/')
def home(): return "Ø§Ù„Ø¨ÙˆØª Ø´ØºØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­!"

def run():
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)

def keep_alive():
    t = Thread(target=run)
    t.start()

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø© ---
API_TOKEN = '8534031232:AAHwBJ0HZvOlbDmeevlbd2zM9FvSIfeskjk'
bot = telebot.TeleBot(API_TOKEN)
scraper = cloudscraper.create_scraper(browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False})
translator = Translator()

# Ø¨Ù†Ùƒ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø§Ù„Ø¶Ø®Ù… (Ø£ÙƒØ«Ø± Ù…Ù† 100 Ø¬Ù…Ù„Ø©)
price_labels = ["Ø¨ÙƒÙ…ØŸ", "Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­ÙŠÙ†:", "Ø¨ÙƒÙ… Ù‡Ø§Ù„Ø²ÙŠÙ†ØŸ", "Ù‚ÙŠÙ…Ø© Ø§Ù„Ù„Ù‚Ø·Ø©:", "Ø³Ø¹Ø±Ù‡ Ø§Ù„Ù„Ù‚Ø·Ø©:"]
intros = [
    "ÙŠØ§ Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡.. Ø´ÙˆÙÙˆØ§ Ù‡Ø§Ù„Ù„Ù‚Ø·Ø©! ğŸ˜", "Ø¬Ø¨Øª Ù„ÙƒÙ… Ø²ÙŠÙ† Ø§Ù„Ù‚Ù†ØµØ§Øª ğŸ”¥", "Ù„Ù‚Ø·Ø© Ø§Ù„ÙŠÙˆÙ… Ù„Ø§ ØªÙÙˆØªÙƒÙ… âœ¨", 
    "Ø§Ø¨Ø´Ø±ÙˆØ§ Ø¨Ø§Ù„Ø²ÙŠÙ†.. Ø´ÙˆÙÙˆØ§ ÙˆØ´ Ù„Ù‚ÙŠØª ğŸ’", "Ù‚Ù†ØµØ© Ø§Ù„ÙŠÙˆÙ… ÙˆØµÙ„Øª ÙŠØ§Ù„Ø±Ø¨Ø¹ ğŸ¯", "Ù„Ù‚ÙŠØª Ù„ÙƒÙ… Ø´ÙŠ ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³ ğŸ˜",
    "ÙŠØ§ Ù…Ø³Ø§ Ø§Ù„Ø²ÙŠÙ†.. Ø´ÙˆÙÙˆØ§ Ù‡Ø§Ù„Ø¬Ù…Ø§Ù„ ğŸŒ¸", "Ù„Ù‚Ø·Ø© Ø§Ù„ÙŠÙˆÙ… Ù„Ù„ÙŠ ÙŠØ¯ÙˆØ± Ø§Ù„ÙØ®Ø§Ù…Ø© âœ¨", "ÙŠØ§ Ø­ÙŠ Ø§Ù„Ù„Ù‡ Ù‡Ø§Ù„Ø·Ù„Ø©.. Ø´ÙŠ ÙÙ†Ø§Ù† ğŸŒŸ"
]
descs = [
    "Ø´ÙŠØ¡ ÙØ§Ø®Ø± ÙˆÙ…Ù† Ø§Ù„Ø¢Ø®Ø± ÙˆÙŠØ³ØªØ§Ù‡Ù„ÙƒÙ….", "Ø§Ù„Ø²ÙŠÙ† Ù…Ø§ ÙŠÙƒÙ…Ù„ Ø¥Ù„Ø§ Ø¨Ù‡ØŒ Ø¬ÙˆØ¯Ø© ÙˆØ³Ø¹Ø±.", "Ø±Ù‡ÙŠØ¨ ÙˆÙÙ†Ø§Ù† ÙˆØªØµÙ…ÙŠÙ…Ù‡ ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³.", 
    "ØªÙ‚ÙŠÙŠÙ…Ù‡ ÙŠØ·Ù…Ù† ÙˆØ¨ØµØ±Ø§Ø­Ø© Ù…Ø§ ÙŠØªÙÙˆØª.", "Ø®Ø§Ù…Ø© Ù…Ù…ØªØ§Ø²Ø© ÙˆØ³Ø¹Ø±Ù‡Ø§ ÙŠØ§ Ø¨Ù„Ø§Ø´ ÙˆØ§Ù„Ù„Ù‡.", "ÙˆØ§Ù„Ù„Ù‡ Ù„Ùˆ Ù…Ø§Ù‡Ùˆ Ø¨Ø·Ù„ Ù…Ø§ Ø¬Ø¨ØªÙ‡ Ù„ÙƒÙ…."
]

def get_clean_arabic_title(title):
    try:
        # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø§Ø³Ù… Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        translated = translator.translate(title, dest='ar').text
        # Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ù†Øµ Ù„ÙŠÙƒÙˆÙ† Ø³Ø·Ø±ÙŠÙ† (Ø£ÙˆÙ„ 12 ÙƒÙ„Ù…Ø©)
        words = translated.split()
        if len(words) > 12:
            return " ".join(words[:12]) + ".."
        return translated
    except:
        # ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø©ØŒ Ù†Ø±Ø¬Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ø®ØªØµØ±Ø§Ù‹
        words = title.split()
        return " ".join(words[:12]) + ".." if len(words) > 12 else title

def get_product_data(url):
    try:
        res = scraper.get(url, timeout=30)
        soup = BeautifulSoup(res.content, 'html.parser')

        # 1. Ø³Ø­Ø¨ Ø§Ù„Ø§Ø³Ù… ÙˆØªØ±Ø¬Ù…ØªÙ‡ ÙÙˆØ±Ø§Ù‹
        title_tag = soup.select_one('#productTitle') or soup.find("meta", property="og:title")
        product_info = "Ù…Ù†ØªØ¬ ÙØ®Ù…"
        if title_tag:
            raw_title = title_tag.get_text().strip()
            product_info = get_clean_arabic_title(raw_title)

        # 2. Ø³Ø­Ø¨ Ø§Ù„Ø³Ø¹Ø± (Ø¨Ø¯ÙˆÙ† Ù‡Ù„Ù„Ø§Øª ÙˆØ¨Ø¯ÙˆÙ† Ù†Ù‚Ø§Ø·)
        price = "Ø´ÙŠÙƒ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· ğŸ·ï¸"
        selectors = [
            'span.a-price-whole', '.a-price .a-offscreen', 
            '#corePrice_feature_div .a-offscreen', '#corePriceDisplay_desktop_feature_div .a-offscreen'
        ]
        for sel in selectors:
            p_tag = soup.select_one(sel)
            if p_tag and p_tag.get_text().strip():
                p_text = p_tag.get_text().strip().split('.')[0]
                clean_p = re.sub(r'[^\d]', '', p_text)
                if clean_p:
                    price = f"{clean_p} Ø±ÙŠØ§Ù„"
                    break

        # 3. Ø³Ø­Ø¨ Ø§Ù„ØµÙˆØ±Ø©
        img_url = None
        img_tag = soup.select_one('#landingImage') or soup.select_one('#main-image')
        if img_tag and img_tag.has_attr('data-a-dynamic-image'):
            links = re.findall(r'(https?://[^\s"]+)', img_tag['data-a-dynamic-image'])
            img_url = links[-1] if links else img_tag.get('src')
        elif img_tag:
            img_url = img_tag.get('src')

        caption = (
            f"{random.choice(intros)}\n\n"
            f"ğŸ“¦ **Ø§Ù„Ù…Ù†ØªØ¬:** {product_info}\n\n"
            f"ğŸ’° **{random.choice(price_labels)}** {price}\n"
            f"ğŸ‘Œ {random.choice(descs)}\n\n"
            f"ğŸ”— **Ø±Ø§Ø¨Ø· Ø§Ù„Ø·Ù„Ø¨:** {url}"
        )
        return caption, img_url
    except:
        return None, None

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    if "http" in message.text:
        url_match = re.search(r'(https?://\S+)', message.text)
        if url_match:
            url = url_match.group(0)
            bot.send_chat_action(message.chat.id, 'upload_photo')
            caption, img_url = get_product_data(url)
            if caption:
                try:
                    if img_url: bot.send_photo(message.chat.id, img_url, caption=caption, parse_mode='Markdown')
                    else: bot.send_message(message.chat.id, caption, parse_mode='Markdown')
                except:
                    bot.send_message(message.chat.id, caption, parse_mode='Markdown')

if __name__ == "__main__":
    keep_alive()
    bot.polling(none_stop=True)
