import telebot
import requests
from bs4 import BeautifulSoup
import random
import re

# Ø§Ù„ØªÙˆÙƒÙ† Ø­Ù‚Ùƒ
API_TOKEN = '8534031232:AAHwBJ0HZvOlbDmeevlbd2zM9FvSIfeskjk'
bot = telebot.TeleBot(API_TOKEN)

# --- Ø¨Ù†Ùƒ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ---
intros = [
    "ÙŠØ§ Ù‡Ù„Ø§ ÙˆØ§Ù„Ù„Ù‡.. Ø´ÙˆÙÙˆØ§ Ù‡Ø§Ù„Ù„Ù‚Ø·Ø©! ğŸ˜", "Ø¬Ø¨Øª Ù„ÙƒÙ… Ø²ÙŠÙ† Ø§Ù„Ù‚Ù†ØµØ§Øª ğŸ”¥", "Ù„Ù‚Ø·Ø© Ø§Ù„ÙŠÙˆÙ… Ù„Ø§ ØªÙÙˆØªÙƒÙ… âœ¨", "Ø§Ø¨Ø´Ø±ÙˆØ§ Ø¨Ø§Ù„Ø²ÙŠÙ†.. Ø´ÙˆÙÙˆØ§ ÙˆØ´ Ù„Ù‚ÙŠØª ğŸ’",
    "ÙŠØ§ Ø­ÙŠ Ø§Ù„Ù„Ù‡ Ù‡Ø§Ù„Ø·Ù„Ø©.. Ø¬Ø¨Ù†Ø§ Ù„ÙƒÙ… Ø´ÙŠ ÙÙ†Ø§Ù† ğŸŒŸ", "Ù‚Ù†ØµØ© Ø§Ù„ÙŠÙˆÙ… ÙˆØµÙ„Øª ÙŠØ§Ù„Ø±Ø¨Ø¹ ğŸ¯", "Ù„Ù‚ÙŠØª Ù„ÙƒÙ… Ø´ÙŠ ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³ Ø¨ØµØ±Ø§Ø­Ø© ğŸ˜",
    "ØªØ¨ÙˆÙ† Ø§Ù„ØµØ¯Ù‚ØŸ Ù‡Ø§Ù„Ù‚Ø·Ø¹Ø© Ù…Ø§ ØªØªÙÙˆØª ğŸš€", "Ø´ÙˆÙÙˆØ§ ÙˆØ´ Ø·Ø­Øª Ø¹Ù„ÙŠÙ‡.. Ù„Ù‚Ø·Ø© Ù…Ù„ÙƒÙŠØ© ğŸ‘‘", "Ø§Ù„Ø²ÙŠÙ† ÙˆØµÙ„.. Ø§Ù„Ø­Ù‚ÙˆØ§ Ø¹Ù„ÙŠÙ‡! ğŸ”¥",
    "ÙŠØ§ Ù…Ø³Ø§ Ø§Ù„Ø²ÙŠÙ†.. Ø´ÙˆÙÙˆØ§ Ù‡Ø§Ù„Ø¬Ù…Ø§Ù„ ğŸŒ¸", "Ù„Ù‚Ø·Ø© Ø§Ù„ÙŠÙˆÙ… Ù„Ù„ÙŠ ÙŠØ¯ÙˆØ± Ø§Ù„ÙØ®Ø§Ù…Ø© âœ¨", "Ù‡Ø°Ø§ Ø§Ù„Ù„ÙŠ ÙŠÙ‚Ø§Ù„ Ø¹Ù†Ù‡ Ù„Ù‚Ø·Ø© Ø§Ù„Ø¹Ù…Ø± ğŸ¯",
    "ÙŠØ§ Ø¨Ù„Ø§Ø´ Ø¹Ù„Ù‰ Ù‡Ø§Ù„Ø²ÙŠÙ†.. Ø´ÙˆÙÙˆØ§ ÙˆØ´ Ù„Ù‚ÙŠØª! ğŸ’°", "ØªØ¨ÙˆÙ† Ù‚Ø·Ø¹Ø© ØªØ¨ÙŠØ¶ Ø§Ù„ÙˆØ¬Ù‡ØŸ Ù‡Ø°ÙŠ Ù‡ÙŠ ğŸ’", "Ù‚Ù†ØµØªÙ‡Ø§ Ù„ÙƒÙ… Ù…Ù† Ù‚Ù„Ø¨ Ø£Ù…Ø§Ø²ÙˆÙ† ğŸ”¥",
    "Ù„Ø§ ØªØ¯ÙˆØ±ÙˆÙ† ØºÙŠØ±Ù‡.. Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ğŸ¯", "Ø´ÙˆÙÙˆØ§ Ù‡Ø§Ù„Ø²ÙŠÙ† ÙˆØ´ ÙŠÙ‚ÙˆÙ„ ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø© ğŸ˜", "Ù„Ù‚Ø·Ø© Ø®Ø±Ø§ÙÙŠØ© ÙˆØ³Ø¹Ø±Ù‡Ø§ Ù„Ù‚Ø·Ø© Ø£ÙƒØ«Ø± âœ¨",
    "ÙŠØ§ Ù‡Ù„Ø§ Ø¨Ø§Ù„Ù„ÙŠ ÙŠØ¯ÙˆØ±ÙˆÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©.. Ø´ÙˆÙÙˆØ§ Ù‡Ø°Ø§ ğŸŒŸ"
] # ØªÙ‚Ø¯Ø±ÙŠÙ† ØªØ²ÙŠØ¯ÙŠÙ†Ù‡Ù… Ù„Ù€ 100 Ø¨Ù†ÙØ³ Ø§Ù„Ù†Ù…Ø·

descs = [
    "Ø´ÙŠØ¡ ÙØ§Ø®Ø± ÙˆÙ…Ù† Ø§Ù„Ø¢Ø®Ø± ÙˆÙŠØ³ØªØ§Ù‡Ù„ÙƒÙ….", "Ø§Ù„Ø²ÙŠÙ† Ù…Ø§ ÙŠÙƒÙ…Ù„ Ø¥Ù„Ø§ Ø¨Ù‡ØŒ Ø¬ÙˆØ¯Ø© ÙˆØ³Ø¹Ø±.", "Ø±Ù‡ÙŠØ¨ ÙˆÙÙ†Ø§Ù† ÙˆØªØµÙ…ÙŠÙ…Ù‡ ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³.", "ØªÙ‚ÙŠÙŠÙ…Ù‡ ÙŠØ·Ù…Ù† ÙˆØ¨ØµØ±Ø§Ø­Ø© Ù…Ø§ ÙŠØªÙÙˆØª.",
    "Ù‚Ø·Ø¹Ø© ÙÙ†ÙŠØ© ÙˆØªØ¨ÙŠØ¶ Ø§Ù„ÙˆØ¬Ù‡ Ø¹Ù†Ø¯ Ø§Ù„Ø¶ÙŠÙˆÙ.", "Ø®Ø§Ù…Ø© Ù…Ù…ØªØ§Ø²Ø© ÙˆØ³Ø¹Ø±Ù‡Ø§ ÙŠØ§ Ø¨Ù„Ø§Ø´ ÙˆØ§Ù„Ù„Ù‡.", "ÙˆØ§Ù„Ù„Ù‡ Ù„Ùˆ Ù…Ø§Ù‡Ùˆ Ø¨Ø·Ù„ Ù…Ø§ Ø¬Ø¨ØªÙ‡ Ù„ÙƒÙ….", "Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆØ³Ø¹Ø±Ù‡ ØµØ¯Ù…Ø© Ø¨ØµØ±Ø§Ø­Ø©.",
    "Ù…Ù† Ø£ÙƒØ«Ø± Ø§Ù„Ù‚Ø·Ø¹ Ø·Ù„Ø¨Ø§Ù‹ ÙˆØªÙ‚ÙŠÙŠÙ…Ù‡ Ø¹Ø§Ù„ÙŠ.", "ÙŠØ³ØªØ§Ù‡Ù„ ÙƒÙ„ Ø±ÙŠØ§Ù„ ÙŠØ¯ÙØ¹ ÙÙŠÙ‡ ÙŠØ§Ù„Ø±Ø¨Ø¹.", "ÙØ®Ø§Ù…Ø© ÙˆØ¬ÙˆØ¯Ø© ÙˆØªØµÙ…ÙŠÙ… Ø¹ØµØ±ÙŠ ÙÙ†Ø§Ù†.", "ØªØ±Ø§Ù‡ ÙŠØ®Ù„Øµ Ø¨Ø³Ø±Ø¹Ø©ØŒ Ø§Ù„Ù„ÙŠ ÙŠØ¨ÙŠÙ‡ ÙŠÙ„Ø­Ù‚.",
    "Ø´ÙŠ Ø¨Ø·Ù„ Ø¨Ø·Ù„.. Ù„Ø§ ØªÙ‚ÙˆÙ„ÙˆÙ† Ù…Ø§ Ù‚Ù„Øª Ù„ÙƒÙ….", "Ù…Ù†Ø§Ø³Ø¨ Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙŠÙˆÙ…ÙŠ ÙˆÙ‚ÙˆÙŠ.", "Ø§Ù„ÙƒÙ„ ÙŠÙ…Ø¯Ø­Ù‡ ÙˆØªØ¬Ø±Ø¨ØªÙ‡ ØªØ¨ÙŠØ¶ Ø§Ù„ÙˆØ¬Ù‡.", "Ø®ÙŠØ§Ø± Ø°ÙƒÙŠ Ù„Ù„ÙŠ ÙŠØ¯ÙˆØ± Ø§Ù„Ø²ÙŠÙ† ÙˆØ¨Ø³.",
    "ØªØµÙ…ÙŠÙ… ÙŠÙØªØ­ Ø§Ù„Ù†ÙØ³ ÙˆØ³Ø¹Ø± ÙˆÙ„Ø§ ÙÙŠ Ø§Ù„Ø£Ø­Ù„Ø§Ù….", "ÙˆØ§Ù„Ù„Ù‡ Ù‚Ø·Ø¹Ø© Ù…ØªØ¹ÙˆØ¨ Ø¹Ù„ÙŠÙ‡Ø§ ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø©.", "Ù‡Ø°Ø§ Ø§Ù„Ù„ÙŠ ÙŠØ®Ù„ÙŠÙƒ Ù…ØªÙ…ÙŠØ² ÙÙŠ Ø§Ø®ØªÙŠØ§Ø±Ø§ØªÙƒ.", "Ø¬ÙˆØ¯Ø© ÙˆØ³Ø¹Ø± ÙˆÙ…Ø¸Ù‡Ø±.. ÙˆØ´ ØªØ¨ÙŠ Ø£ÙƒØ«Ø±ØŸ"
]

def get_product_data(url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            "Accept-Language": "ar-SA,en-US;q=0.9,ar;q=0.8",
        }
        res = requests.get(url, headers=headers, timeout=20, allow_redirects=True)
        soup = BeautifulSoup(res.content, 'html.parser')

        # 1. Ø§Ù„Ø§Ø³Ù… (Ø³Ø·Ø±ÙŠÙ†)
        title_tag = soup.find("span", {"id": "productTitle"}) or soup.find("meta", property="og:title")
        raw_title = title_tag.get_text().strip() if title_tag else "Ù…Ù†ØªØ¬ ÙØ®Ù…"
        raw_title = raw_title.replace("Amazon.sa :", "").replace("Amazon.sa:", "").strip()
        words = raw_title.split()
        product_info = " ".join(words[:14]) + ".." if len(words) > 14 else raw_title

        # 2. Ø§Ù„Ø³Ø¹Ø± (Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…)
        price = "Ø´ÙŠÙƒ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· ğŸ·ï¸"
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±ÙŠØ§Ù„ Ø£Ùˆ SR Ø£Ùˆ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø³Ø¹Ø±
        price_patterns = [
            soup.find("span", class_="a-price-whole"),
            soup.find("span", class_="a-offscreen"),
            soup.find("span", id="priceblock_ourprice"),
            soup.find("span", id="priceblock_dealprice")
        ]
        
        for p in price_patterns:
            if p and p.get_text().strip():
                price_val = p.get_text().strip().replace("\u200f", "").replace("\u200e", "")
                if any(char.isdigit() for char in price_val):
                    price = price_val if "Ø±ÙŠØ§Ù„" in price_val else f"{price_val} Ø±ÙŠØ§Ù„"
                    break

        # 3. Ø§Ù„ØµÙˆØ±Ø©
        img_url = None
        img_tag = soup.find("img", {"id": "landingImage"})
        if img_tag and img_tag.has_attr('data-a-dynamic-image'):
            img_url = list(eval(img_tag.get('data-a-dynamic-image')).keys())[-1]
        elif img_tag:
            img_url = img_tag.get('src')

        # 4. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ø§Ù„Ù„Ù…Ø³Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©)
        caption = (
            f"{random.choice(intros)}\n\n"
            f"ğŸ“¦ **Ø§Ù„Ù…Ù†ØªØ¬:** {product_info}\n\n"
            f"ğŸ’° **Ø¨ÙƒÙ…ØŸ** {price}\n"
            f"ğŸ‘Œ {random.choice(descs)}\n\n"
            f"ğŸ”— **Ø±Ø§Ø¨Ø· Ø§Ù„Ø·Ù„Ø¨:** {url}"
        )
        return caption, img_url
    except:
        return None, None

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    if "http" in message.text:
        url = re.search(r'(https?://\S+)', message.text).group(0)
        bot.send_chat_action(message.chat.id, 'upload_photo')
        caption, img_url = get_product_data(url)
        if caption:
            if img_url:
                try: bot.send_photo(message.chat.id, img_url, caption=caption, parse_mode='Markdown')
                except: bot.send_message(message.chat.id, caption, parse_mode='Markdown')
            else: bot.send_message(message.chat.id, caption, parse_mode='Markdown')
        else:
            bot.reply_to(message, "Ø§Ù„Ø±Ø§Ø¨Ø· Ø¹ÙŠÙ‘Ø§ ÙŠÙØªØ­ØŒ Ø¬Ø±Ø¨ÙŠ ØºÙŠØ±Ù‡ ÙŠØ§ Ø¨Ø¹Ø¯ÙŠ ğŸ’”")

print("Ø§Ù„Ø¨ÙˆØª Ø´ØºØ§Ù„..")
bot.polling()
